"""
è´¨é‡ç›‘æ§æœåŠ¡
ç›‘æ§å·²éƒ¨ç½²æœåŠ¡çš„è´¨é‡æŒ‡æ ‡ï¼Œè‡ªåŠ¨è§¦å‘ä¼˜åŒ–
"""
import logging
from typing import Optional, Dict, List
from datetime import datetime, timedelta
import numpy as np

from backend.database.connection import AsyncSessionLocal
from backend.models.mcp_service import MCPService, ServiceStatus
from backend.models.service_log import ServiceLog

logger = logging.getLogger(__name__)


class QualityMonitor:
    """è´¨é‡ç›‘æ§å™¨"""
    
    # è´¨é‡é˜ˆå€¼é…ç½®
    THRESHOLDS = {
        "error_rate": 0.05,      # 5%é”™è¯¯ç‡
        "p99_latency": 1000,     # 1ç§’P99å»¶è¿Ÿ
        "avg_latency": 500       # 500mså¹³å‡å»¶è¿Ÿ
    }
    
    def __init__(self):
        """åˆå§‹åŒ–è´¨é‡ç›‘æ§å™¨"""
        self.metrics_cache: Dict[str, dict] = {}
        logger.info("QualityMonitor initialized")
    
    async def collect_metrics(
        self,
        service_id: str,
        window: str = "1h"
    ) -> dict:
        """
        æ”¶é›†æœåŠ¡æŒ‡æ ‡
        
        Args:
            service_id: æœåŠ¡ID
            window: æ—¶é—´çª—å£(1h, 6h, 24h, 7d)
            
        Returns:
            dict: æŒ‡æ ‡æ•°æ®
        """
        # è§£ææ—¶é—´çª—å£
        window_seconds = self._parse_time_window(window)
        start_time = datetime.utcnow() - timedelta(seconds=window_seconds)
        
        async with AsyncSessionLocal() as db:
            from sqlalchemy import select, and_
            
            # æŸ¥è¯¢æ—¥å¿—
            stmt = select(ServiceLog).where(
                and_(
                    ServiceLog.service_id == service_id,
                    ServiceLog.created_at >= start_time
                )
            )
            result = await db.execute(stmt)
            logs = result.scalars().all()
            
            if not logs:
                return {
                    "service_id": service_id,
                    "window": window,
                    "total_requests": 0,
                    "error_rate": 0.0,
                    "p99_latency": 0.0,
                    "avg_latency": 0.0,
                    "qps": 0.0
                }
            
            # è®¡ç®—æŒ‡æ ‡
            total_requests = len(logs)
            errors = [l for l in logs if l.status == "error"]
            error_rate = len(errors) / total_requests if total_requests > 0 else 0
            
            # å»¶è¿Ÿç»Ÿè®¡
            latencies = [l.latency for l in logs if l.latency is not None]
            p99_latency = np.percentile(latencies, 99) if latencies else 0
            avg_latency = np.mean(latencies) if latencies else 0
            
            # QPSè®¡ç®—
            qps = total_requests / window_seconds if window_seconds > 0 else 0
            
            metrics = {
                "service_id": service_id,
                "window": window,
                "total_requests": total_requests,
                "error_rate": round(error_rate, 4),
                "p99_latency": round(p99_latency, 2),
                "avg_latency": round(avg_latency, 2),
                "qps": round(qps, 2),
                "success_count": total_requests - len(errors),
                "error_count": len(errors),
                "collected_at": datetime.utcnow().isoformat()
            }
            
            # ç¼“å­˜ç»“æœ
            self.metrics_cache[service_id] = metrics
            
            return metrics
    
    async def auto_refine_if_needed(self, service_id: str) -> Optional[str]:
        """
        å½“è´¨é‡æŒ‡æ ‡ä½äºé˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨è§¦å‘MCPybarraé‡æ–°ä¼˜åŒ–
        
        Args:
            service_id: æœåŠ¡ID
            
        Returns:
            Optional[str]: æ–°æœåŠ¡ID(å¦‚æœè§¦å‘äº†ä¼˜åŒ–)
        """
        logger.info(f"Checking quality metrics for service {service_id}")
        
        # æ”¶é›†æœ€è¿‘1å°æ—¶çš„æŒ‡æ ‡
        metrics = await self.collect_metrics(service_id, window="1h")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
        should_refine = (
            metrics["error_rate"] > self.THRESHOLDS["error_rate"] or
            metrics["p99_latency"] > self.THRESHOLDS["p99_latency"]
        )
        
        if not should_refine:
            logger.info(f"Service {service_id} quality is acceptable")
            return None
        
        logger.warning(
            f"Service {service_id} quality degraded. "
            f"Error rate: {metrics['error_rate']*100:.1f}%, "
            f"P99 latency: {metrics['p99_latency']:.0f}ms"
        )
        
        # è·å–åŸå§‹æœåŠ¡é…ç½®
        async with AsyncSessionLocal() as db:
            from sqlalchemy import select
            result = await db.execute(select(MCPService).where(MCPService.id == service_id))
            service = result.scalar_one_or_none()
            
            if not service:
                logger.error(f"Service {service_id} not found")
                return None
            
            # æ„å»ºå¢å¼ºçš„ä¼˜åŒ–éœ€æ±‚
            enhanced_requirement = f"""
åŸå§‹éœ€æ±‚ï¼š
{service.original_requirement}

å½“å‰é—®é¢˜åˆ†æï¼š
- é”™è¯¯ç‡ï¼š{metrics['error_rate']*100:.1f}% (é˜ˆå€¼ï¼š{self.THRESHOLDS['error_rate']*100}%)
- P99å»¶è¿Ÿï¼š{metrics['p99_latency']:.0f}ms (é˜ˆå€¼ï¼š{self.THRESHOLDS['p99_latency']}ms)
- å¹³å‡å»¶è¿Ÿï¼š{metrics['avg_latency']:.0f}ms

ä¼˜åŒ–è¦æ±‚ï¼š
1. åŠ å¼ºé”™è¯¯å¤„ç†å’Œè¾“å…¥éªŒè¯
2. ä¼˜åŒ–æ€§èƒ½ï¼Œå‡å°‘å»¶è¿Ÿ
3. æ·»åŠ é‡è¯•æœºåˆ¶å’Œç†”æ–­å™¨
4. æ”¹è¿›æ—¥å¿—è®°å½•ä»¥ä¾¿è°ƒè¯•

è¯·åŸºäºä»¥ä¸Šé—®é¢˜é‡æ–°ç”Ÿæˆé«˜è´¨é‡çš„æœåŠ¡ä»£ç ã€‚
"""
            
            # å¯åŠ¨æ–°çš„ç”Ÿæˆä»»åŠ¡
            from backend.services.service_manager import ServiceManager
            service_manager = ServiceManager()
            
            new_task_id = await service_manager.start_generation(
                user_input=enhanced_requirement,
                farmer_id=service.farmer_id,
                model=service.model_used,
                request_id=f"auto_refine_{service_id}"
            )
            
            # æ ‡è®°æ–°æœåŠ¡ä¸ºä¼˜åŒ–ç‰ˆæœ¬
            async with AsyncSessionLocal() as db2:
                from sqlalchemy import select
                stmt = select(MCPService).where(MCPService.id == new_task_id)
                result = await db2.execute(stmt)
                new_service = result.scalar_one()
                
                new_service.parent_service_id = service_id
                new_service.description = f"Auto-refined version of {service_id}"
                
                # æ›´æ–°åŸæœåŠ¡çš„ä¼˜åŒ–è®¡æ•°
                service.refinement_count += 1
                
                await db2.commit()
            
            logger.info(f"Auto-refinement triggered for {service_id}, new service: {new_task_id}")
            return new_task_id
    
    async def generate_quality_report(
        self,
        service_id: str,
        window: str = "7d"
    ) -> str:
        """
        ç”Ÿæˆè´¨é‡è¯„ä¼°æŠ¥å‘Š(Markdownæ ¼å¼)
        
        Args:
            service_id: æœåŠ¡ID
            window: ç»Ÿè®¡å‘¨æœŸ
            
        Returns:
            str: Markdownæ ¼å¼æŠ¥å‘Š
        """
        metrics = await self.collect_metrics(service_id, window)
        
        async with AsyncSessionLocal() as db:
            from sqlalchemy import select
            result = await db.execute(select(MCPService).where(MCPService.id == service_id))
            service = result.scalar_one_or_none()
            
            if not service:
                return f"# é”™è¯¯\n\næœåŠ¡ {service_id} ä¸å­˜åœ¨"
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# æœåŠ¡è´¨é‡æŠ¥å‘Š

**æœåŠ¡åç§°**: {service.name}  
**æœåŠ¡ID**: {service_id}  
**ç”Ÿæˆæ—¶é—´**: {service.created_at.strftime('%Y-%m-%d %H:%M:%S')}  
**ç»Ÿè®¡å‘¨æœŸ**: {window}  
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}

---

## æ€§èƒ½æŒ‡æ ‡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ | é˜ˆå€¼ |
|------|------|------|------|
| æ€»è¯·æ±‚æ•° | {metrics['total_requests']} | - | - |
| æˆåŠŸè¯·æ±‚ | {metrics['success_count']} | - | - |
| å¤±è´¥è¯·æ±‚ | {metrics['error_count']} | - | - |
| é”™è¯¯ç‡ | {metrics['error_rate']*100:.2f}% | {self._get_status_emoji(metrics['error_rate'], self.THRESHOLDS['error_rate'])} | <{self.THRESHOLDS['error_rate']*100}% |
| P99å»¶è¿Ÿ | {metrics['p99_latency']:.0f}ms | {self._get_status_emoji(metrics['p99_latency'], self.THRESHOLDS['p99_latency'])} | <{self.THRESHOLDS['p99_latency']}ms |
| å¹³å‡å»¶è¿Ÿ | {metrics['avg_latency']:.0f}ms | {self._get_status_emoji(metrics['avg_latency'], self.THRESHOLDS['avg_latency'])} | <{self.THRESHOLDS['avg_latency']}ms |
| QPS | {metrics['qps']:.2f} | - | - |

---

## è¯¦ç»†åˆ†æ

### 1. å¯ç”¨æ€§åˆ†æ

- **å¯ç”¨æ€§**: {((1 - metrics['error_rate']) * 100):.2f}%
- **è¯„çº§**: {self._get_availability_rating(metrics['error_rate'])}

{self._get_availability_analysis(metrics['error_rate'])}

### 2. æ€§èƒ½åˆ†æ

{self._get_performance_analysis(metrics)}

### 3. ä¼˜åŒ–å»ºè®®

{self._generate_recommendations(metrics)}

---

## å†å²è¶‹åŠ¿

*æ³¨ï¼šå®Œæ•´çš„å†å²è¶‹åŠ¿åˆ†æéœ€è¦æ—¶åºæ•°æ®åº“æ”¯æŒï¼Œå½“å‰ç‰ˆæœ¬æ˜¾ç¤ºå½“å‰å¿«ç…§*

- **å½“å‰çŠ¶æ€**: {"ğŸŸ¢ å¥åº·" if self._is_healthy(metrics) else "ğŸ”´ éœ€è¦å…³æ³¨"}
- **ä¸Šæ¬¡ä¼˜åŒ–**: {service.refinement_count} æ¬¡
- **éƒ¨ç½²çŠ¶æ€**: {"âœ… å·²éƒ¨ç½²" if service.is_deployed else "â¸ï¸ æœªéƒ¨ç½²"}

---

*æœ¬æŠ¥å‘Šç”±æ™ºå†œé“¾é”€è´¨é‡ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
        
        return report
    
    def _parse_time_window(self, window: str) -> int:
        """
        è§£ææ—¶é—´çª—å£ä¸ºç§’æ•°
        
        Args:
            window: æ—¶é—´çª—å£å­—ç¬¦ä¸²(å¦‚"1h", "7d")
            
        Returns:
            int: ç§’æ•°
        """
        window_map = {
            "1h": 3600,
            "6h": 21600,
            "24h": 86400,
            "7d": 604800,
            "30d": 2592000
        }
        return window_map.get(window, 3600)
    
    def _get_status_emoji(self, value: float, threshold: float) -> str:
        """è·å–çŠ¶æ€è¡¨æƒ…"""
        if value < threshold:
            return "âœ…"
        elif value < threshold * 1.5:
            return "âš ï¸"
        else:
            return "âŒ"
    
    def _get_availability_rating(self, error_rate: float) -> str:
        """è·å–å¯ç”¨æ€§è¯„çº§"""
        availability = (1 - error_rate) * 100
        if availability >= 99.9:
            return "ä¼˜ç§€ (Three 9s)"
        elif availability >= 99.0:
            return "è‰¯å¥½ (Two 9s)"
        elif availability >= 95.0:
            return "åŠæ ¼"
        else:
            return "ä¸åˆæ ¼"
    
    def _get_availability_analysis(self, error_rate: float) -> str:
        """è·å–å¯ç”¨æ€§åˆ†ææ–‡æœ¬"""
        if error_rate < 0.01:
            return "âœ… æœåŠ¡å¯ç”¨æ€§ä¼˜ç§€ï¼Œé”™è¯¯ç‡æ§åˆ¶è‰¯å¥½ã€‚"
        elif error_rate < 0.05:
            return "âš ï¸ æœåŠ¡å¯ç”¨æ€§è‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚å»ºè®®å…³æ³¨é”™è¯¯æ—¥å¿—ã€‚"
        else:
            return "âŒ æœåŠ¡å¯ç”¨æ€§ä¸è¾¾æ ‡ï¼Œéœ€è¦ç«‹å³ä¼˜åŒ–ã€‚å»ºè®®å¯ç”¨è‡ªåŠ¨ä¼˜åŒ–åŠŸèƒ½ã€‚"
    
    def _get_performance_analysis(self, metrics: dict) -> str:
        """è·å–æ€§èƒ½åˆ†ææ–‡æœ¬"""
        analysis = []
        
        if metrics['p99_latency'] < self.THRESHOLDS['p99_latency']:
            analysis.append("- âœ… P99å»¶è¿Ÿè¡¨ç°ä¼˜ç§€")
        else:
            analysis.append(f"- âŒ P99å»¶è¿Ÿè¿‡é«˜({metrics['p99_latency']:.0f}ms)ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–å¢åŠ ç¼“å­˜")
        
        if metrics['avg_latency'] < self.THRESHOLDS['avg_latency']:
            analysis.append("- âœ… å¹³å‡å»¶è¿Ÿè¡¨ç°è‰¯å¥½")
        else:
            analysis.append(f"- âš ï¸ å¹³å‡å»¶è¿Ÿåé«˜({metrics['avg_latency']:.0f}ms)ï¼Œå»ºè®®è¿›è¡Œæ€§èƒ½åˆ†æ")
        
        if metrics['qps'] > 0:
            analysis.append(f"- ğŸ“Š å½“å‰QPSä¸º {metrics['qps']:.2f}ï¼ŒæœåŠ¡è´Ÿè½½æ­£å¸¸")
        
        return "\n".join(analysis)
    
    def _generate_recommendations(self, metrics: dict) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if metrics['error_rate'] > self.THRESHOLDS['error_rate']:
            recommendations.append("### ğŸ”´ é”™è¯¯ç‡ä¼˜åŒ–")
            recommendations.append("- åŠ å¼ºè¾“å…¥éªŒè¯å’Œå¼‚å¸¸å¤„ç†")
            recommendations.append("- æ·»åŠ é‡è¯•æœºåˆ¶(å¸¦æŒ‡æ•°é€€é¿)")
            recommendations.append("- å®ç°ç†”æ–­å™¨æ¨¡å¼é˜²æ­¢çº§è”å¤±è´¥")
            recommendations.append("- è¯¦ç»†è®°å½•é”™è¯¯æ—¥å¿—ä»¥ä¾¿æ’æŸ¥")
        
        if metrics['p99_latency'] > self.THRESHOLDS['p99_latency']:
            recommendations.append("### âš¡ æ€§èƒ½ä¼˜åŒ–")
            recommendations.append("- ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢(æ·»åŠ ç´¢å¼•ã€å‡å°‘N+1æŸ¥è¯¢)")
            recommendations.append("- å¼•å…¥ç¼“å­˜å±‚(Redis)å‡å°‘é‡å¤è®¡ç®—")
            recommendations.append("- ä½¿ç”¨å¼‚æ­¥I/Oæå‡å¹¶å‘èƒ½åŠ›")
            recommendations.append("- è€ƒè™‘ä½¿ç”¨CDNåŠ é€Ÿé™æ€èµ„æº")
        
        if metrics['total_requests'] < 10:
            recommendations.append("### ğŸ“Š æ•°æ®ä¸è¶³")
            recommendations.append("- å½“å‰è¯·æ±‚é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æµ‹è¯•ç”¨ä¾‹")
            recommendations.append("- å¯ä»¥ä½¿ç”¨å‹åŠ›æµ‹è¯•å·¥å…·æ¨¡æ‹ŸçœŸå®è´Ÿè½½")
        
        if not recommendations:
            recommendations.append("### âœ… å½“å‰æœåŠ¡è´¨é‡è‰¯å¥½")
            recommendations.append("- ç»§ç»­ä¿æŒï¼Œå®šæœŸç›‘æ§æŒ‡æ ‡å˜åŒ–")
            recommendations.append("- å»ºè®®è®¾ç½®è‡ªåŠ¨å‘Šè­¦ï¼ŒåŠæ—¶å‘ç°é—®é¢˜")
        
        return "\n".join(recommendations)
    
    def _is_healthy(self, metrics: dict) -> bool:
        """åˆ¤æ–­æœåŠ¡æ˜¯å¦å¥åº·"""
        return (
            metrics['error_rate'] <= self.THRESHOLDS['error_rate'] and
            metrics['p99_latency'] <= self.THRESHOLDS['p99_latency']
        )

    async def check_service_quality(self, service_id: str) -> bool:
        """
        æ£€æŸ¥æœåŠ¡è´¨é‡æ˜¯å¦è¾¾æ ‡
        
        Args:
            service_id: æœåŠ¡ID
            
        Returns:
            bool: Trueè¡¨ç¤ºè´¨é‡è¾¾æ ‡ï¼ŒFalseè¡¨ç¤ºéœ€è¦ä¼˜åŒ–
        """
        try:
            metrics = await self.collect_metrics(service_id, window="1h")
            
            # å¦‚æœè¯·æ±‚é‡å¤ªå°‘ï¼Œé»˜è®¤è®¤ä¸ºè´¨é‡OK
            if metrics['total_requests'] < 5:
                return True
            
            is_healthy = self._is_healthy(metrics)
            
            if not is_healthy:
                logger.warning(
                    f"Service {service_id} quality check failed. "
                    f"Error rate: {metrics['error_rate']*100:.1f}%, "
                    f"P99 latency: {metrics['p99_latency']:.0f}ms"
                )
            
            return is_healthy
            
        except Exception as e:
            logger.error(f"Failed to check quality for {service_id}: {e}")
            return True  # å‡ºé”™æ—¶ä¸è§¦å‘ä¼˜åŒ–
